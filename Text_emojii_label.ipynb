{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31902,
     "status": "ok",
     "timestamp": 1740818369524,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "vhCly-mfCzG6",
    "outputId": "5f143b57-1893-4c45-fcec-0df03b91b1c3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8750,
     "status": "ok",
     "timestamp": 1740818378271,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "01CgKAxiETbr",
    "outputId": "a0b01f0c-b77f-4e5d-c857-a10436175f76"
   },
   "outputs": [],
   "source": [
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27028,
     "status": "ok",
     "timestamp": 1740818405306,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "VFm9OpwvDD5P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1740818405340,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "ekqOIhITENUT"
   },
   "outputs": [],
   "source": [
    "def clean_text_spacy(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text)\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower().strip()\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3645,
     "status": "ok",
     "timestamp": 1740818408987,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "5JMXetvlENRr"
   },
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/Python/shree/Text_emoji_label/data.new.xlsx\"\n",
    "\n",
    "try:\n",
    "    if file_path.endswith(\".xlsx\") or file_path.endswith(\".xls\"):\n",
    "        df = pd.read_excel(file_path)\n",
    "    elif file_path.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_path, delimiter=\",\", on_bad_lines=\"skip\", encoding=\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format! Please provide a CSV or Excel file.\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading dataset: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1740818409045,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "3RVv9-6WENO7"
   },
   "outputs": [],
   "source": [
    "if \"text\" not in df.columns or \"label\" not in df.columns:\n",
    "    raise ValueError(\"Dataset must contain 'text' and 'label' columns!\")\n",
    "\n",
    "df = df.dropna(subset=[\"label\"])  \n",
    "\n",
    "label_mapping = {\"ham\": 0, \"spam\": 1}  \n",
    "df[\"label\"] = df[\"label\"].astype(str).str.lower().map(label_mapping)\n",
    "\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 90026,
     "status": "ok",
     "timestamp": 1740818499085,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "CdYrvVacENMj"
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].fillna(\"\") \n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text_spacy)\n",
    "\n",
    "df = df[df[\"clean_text\"].str.strip() != \"\"]\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"No valid samples found after text cleaning. Please check your dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1740818500072,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "BIXKrLiqYB3R",
    "outputId": "76d1cd6f-2efe-494c-e818-59d712101b8d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df[\"label\"], palette=[\"blue\", \"red\"])\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Ham (Not Spam)\", \"Spam\"])\n",
    "plt.xlabel(\"Message Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Spam vs. Ham Messages\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1740818501774,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "q9EeB6AGYB_Q",
    "outputId": "cecb466a-0bd4-4bac-f03e-4f305d4192b2"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "spam_words = \" \".join(df[df[\"label\"] == 1][\"clean_text\"])\n",
    "spam_wordcloud = WordCloud(width=600, height=400, background_color=\"grey\").generate(spam_words)\n",
    "\n",
    "fig,ax= plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.imshow(spam_wordcloud, interpolation=\"bilinear\")\n",
    "ax.set_title(\"Spam Word Cloud\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1740818502143,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "RyeHTfL2bMMq",
    "outputId": "82d0ff2a-3d81-4631-c996-809e2015e1f9"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ham_words = \" \".join(df[df[\"label\"] == 0][\"clean_text\"])\n",
    "ham_wordcloud = WordCloud(width=600, height=400, background_color=\"white\").generate(ham_words)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  \n",
    "\n",
    "ax.imshow(ham_wordcloud, interpolation=\"bilinear\")\n",
    "ax.set_title(\"Ham (Not Spam) Word Cloud\")\n",
    "ax.axis(\"off\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1740818502175,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "Xylb4bQoYCHb",
    "outputId": "9217cfbd-dde3-425c-ae26-354f7bab36ef"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_bigrams(texts, top_n=15):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,2), stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    bigram_counts = X.toarray().sum(axis=0)\n",
    "    bigram_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    return pd.DataFrame(sorted(zip(bigram_names, bigram_counts), key=lambda x: x[1], reverse=True)[:top_n],\n",
    "                        columns=[\"Bigram\", \"Count\"])\n",
    "\n",
    "spam_bigrams = get_top_bigrams(df[df[\"label\"] == 1][\"clean_text\"])\n",
    "ham_bigrams = get_top_bigrams(df[df[\"label\"] == 0][\"clean_text\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.barplot(y=spam_bigrams[\"Bigram\"], x=spam_bigrams[\"Count\"], palette=\"Reds_r\")\n",
    "ax.set_title(\"Top 15 Bigrams in Spam Messages\")\n",
    "ax.set_xlabel(\"Count\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1740818502685,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "LCEyyHqhcAsh",
    "outputId": "0d0225ea-c139-47d5-a2aa-3a900743ab4e"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_bigrams(texts, top_n=15):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,2), stop_words=\"english\")\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    bigram_counts = X.toarray().sum(axis=0)\n",
    "    bigram_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    return pd.DataFrame(sorted(zip(bigram_names, bigram_counts), key=lambda x: x[1], reverse=True)[:top_n],\n",
    "                        columns=[\"Bigram\", \"Count\"])\n",
    "\n",
    "spam_bigrams = get_top_bigrams(df[df[\"label\"] == 1][\"clean_text\"])\n",
    "ham_bigrams = get_top_bigrams(df[df[\"label\"] == 0][\"clean_text\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(y=ham_bigrams[\"Bigram\"], x=ham_bigrams[\"Count\"], palette=\"Blues_r\")\n",
    "ax.set_title(\"Top 15 Bigrams in Ham Messages\")\n",
    "ax.set_xlabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1740818502999,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "NbZuQfoEYCKD",
    "outputId": "d6d908a9-cdf0-4630-9a45-d67e3256af69"
   },
   "outputs": [],
   "source": [
    "df[\"text_length\"] = df[\"text\"].apply(len)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[df[\"label\"] == 1][\"text_length\"], color=\"red\", label=\"Spam\", kde=True, bins=30)\n",
    "plt.xlabel(\"Message Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Message Length Distribution (Spam vs. Ham)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1740818503338,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "HRki8t5VYCMU",
    "outputId": "06b3b0f4-50b0-47e4-9f40-dc3b7fde9b0e"
   },
   "outputs": [],
   "source": [
    "df[\"text_length\"] = df[\"text\"].apply(len)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.histplot(df[df[\"label\"] == 0][\"text_length\"], color=\"blue\", label=\"Ham\", kde=True, bins=30)\n",
    "plt.xlabel(\"Message Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Message Length Distribution (Spam vs. Ham)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1740818503607,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "uMqoEIcCcmtg",
    "outputId": "0cf3e92d-8369-4530-bae1-749eec9b7ff5"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "special_chars = [\"%\"]\n",
    "for char in special_chars:\n",
    "    df[f\"count_{char}\"] = df[\"text\"].apply(lambda x: x.count(char))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "df.groupby(\"label\")[[\"count_%\"]].mean().T.plot(kind=\"bar\", figsize=(10, 6), colormap=\"coolwarm\")\n",
    "plt.title(\"Average Special Character Count in Spam vs. Ham\")\n",
    "plt.ylabel(\"Average Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1740818503854,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "nRIuwkiFZ5aN",
    "outputId": "a702a4d9-afd3-4718-c974-81e24c34529a"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "special_chars = [\"$\"]\n",
    "for char in special_chars:\n",
    "    df[f\"count_{char}\"] = df[\"text\"].apply(lambda x: x.count(char))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "df.groupby(\"label\")[[\"count_$\"]].mean().T.plot(kind=\"bar\", figsize=(10, 6), colormap=\"coolwarm\")\n",
    "plt.title(\"Average Special Character Count in Spam vs. Ham\")\n",
    "plt.ylabel(\"Average Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1740818504028,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "fQP0ve4OdPYH",
    "outputId": "6cfa2711-69a3-4a92-b837-aff64773a8d8"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "special_chars = [\"!\"]\n",
    "for char in special_chars:\n",
    "    df[f\"count_{char}\"] = df[\"text\"].apply(lambda x: x.count(char))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "df.groupby(\"label\")[[\"count_!\"]].mean().T.plot(kind=\"bar\", figsize=(10, 6), colormap=\"coolwarm\")\n",
    "plt.title(\"Average Special Character Count in Spam vs. Ham\")\n",
    "plt.ylabel(\"Average Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 2983,
     "status": "ok",
     "timestamp": 1740818507013,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "MGFvLCbKZ5Bt",
    "outputId": "221eb102-001a-4e5f-ab6c-5d22b5764c3f"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "df[\"sentiment\"] = df[\"clean_text\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df[df[\"label\"] == 1][\"sentiment\"], color=\"red\", label=\"Spam\", kde=True, bins=30)\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Sentiment Analysis of Spam vs. Ham\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1642,
     "status": "ok",
     "timestamp": 1740818508656,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "l-055cj9aIc9",
    "outputId": "26262f1c-9621-4ad3-e34a-96925111b777"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "df[\"sentiment\"] = df[\"clean_text\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df[df[\"label\"] == 0][\"sentiment\"], color=\"blue\", label=\"Ham\", kde=True, bins=30)\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Sentiment Analysis of Spam vs. Ham\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740818508661,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "ZqRO69buENKL"
   },
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"clean_text\"], df[\"label\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1740818508853,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "8nx9PrFlENHj"
   },
   "outputs": [],
   "source": [
    "# Convert Text to Numerical Representation using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5145,
     "status": "ok",
     "timestamp": 1740818514003,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "qSZpRUsyENE7",
    "outputId": "5073a733-8fa8-4572-fe0a-d355faafefb3"
   },
   "outputs": [],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1740818514032,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "A9eWPzTRENCT",
    "outputId": "44d7236c-9c03-4288-b03b-289676453c3e"
   },
   "outputs": [],
   "source": [
    "# Train Naïve Bayes Classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Naïve Bayes\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1740818514096,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "HjNOgFFPEM9D",
    "outputId": "276fe6d8-56ee-4f06-cac5-4ea6562276f7"
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1740818514551,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "MFEJu5cjEM6z",
    "outputId": "6331a75e-6bb4-4cf4-a418-0cbce6c84c79"
   },
   "outputs": [],
   "source": [
    "# Train KNN Classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=50)\n",
    "knn_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1740818515907,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "oBu3Y-PVEM4L",
    "outputId": "d6c005a9-0677-44b9-9521-147353c56707"
   },
   "outputs": [],
   "source": [
    "# Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5776,
     "status": "ok",
     "timestamp": 1740818521682,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "VDIBiUjJGGq4",
    "outputId": "6d2bcf4b-0fec-4600-9c17-4cf75656268e"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM Classifier\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740818521705,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "wwYDUjvnEM1k",
    "outputId": "f63b1639-9a93-4f51-da46-36665def5549"
   },
   "outputs": [],
   "source": [
    "# Store results in a dictionary\n",
    "results = {\n",
    "    \"Random Forest\": accuracy_score(y_test, y_pred_rf),\n",
    "    \"Naïve Bayes\": accuracy_score(y_test, y_pred_nb),\n",
    "    \"Logistic Regression\": accuracy_score(y_test, y_pred_lr),\n",
    "    \"KNN\": accuracy_score(y_test, y_pred_knn),\n",
    "    \"XGBoost\": accuracy_score(y_test, y_pred_xgb),\n",
    "    \"SVM\": accuracy_score(y_test, y_pred_svm),\n",
    "}\n",
    "\n",
    "# Print Accuracy Comparison\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740818521719,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "Lzqy-5UjGKw3",
    "outputId": "b5a01442-f0c8-4970-bf60-eeafe897b808"
   },
   "outputs": [],
   "source": [
    "# Find the model with the highest accuracy\n",
    "best_model_name = max(results, key=results.get)\n",
    "best_accuracy = results[best_model_name]\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(f\"\\n Best Model: {best_model_name}\")\n",
    "print(f\" Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1740818521740,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "ArHHJcOgH6LF",
    "outputId": "4b250289-653f-407e-f7c8-382195c05698"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Sort models by accuracy and get the top 2\n",
    "top_2_models = sorted(results.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "\n",
    "# Extract model names\n",
    "top_model_1_name, top_model_2_name = top_2_models[0][0], top_2_models[1][0]\n",
    "print(f\" Top 2 Models for Ensemble: {top_model_1_name} & {top_model_2_name}\")\n",
    "\n",
    "# Define the selected models\n",
    "model_mapping = {\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Naïve Bayes\": nb_model,\n",
    "    \"Logistic Regression\": lr_model,\n",
    "    \"KNN\": knn_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "    \"SVM\": svm_model,\n",
    "}\n",
    "\n",
    "# Get the top 2 model instances\n",
    "model_1, model_2 = model_mapping[top_model_1_name], model_mapping[top_model_2_name]\n",
    "\n",
    "\n",
    "# Final ensemble function\n",
    "class EnsembleModel:\n",
    "    def __init__(self, model_1, model_2):\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Get probabilities from both models\n",
    "        prob_1 = self.model_1.predict_proba(X)[:, 1]  # Probability for class 1\n",
    "        prob_2 = self.model_2.predict_proba(X)[:, 1]\n",
    "\n",
    "        # Soft voting (average probabilities)\n",
    "        avg_prob = (prob_1 + prob_2) / 2\n",
    "        return np.vstack([1 - avg_prob, avg_prob]).T  # Convert back to 2-column format\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert probabilities to binary predictions\n",
    "        return np.where(self.predict_proba(X)[:, 1] > 0.5, 1, 0)\n",
    "\n",
    "# Create the ensemble model\n",
    "final_model = EnsembleModel(svm_model, xgb_model)\n",
    "\n",
    "print(\" Ensemble Model (SVM + XGBoost) is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1740818522477,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "66UkSCkXYguR",
    "outputId": "915ca2fc-59d1-4240-a998-6781961787eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get predictions from ensemble model\n",
    "y_pred_ensemble = final_model.predict(X_test_tfidf)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_ensemble)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Ensemble Model (SVM + XGBoost)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1740818523018,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "zxNqXhI8XIvZ",
    "outputId": "807ec307-07bf-43d4-c907-c99cdc688991"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path = \"/content/drive/MyDrive/Python/shree/Text_emoji_label/ensemble_model.pkl\"\n",
    "\n",
    "# Save the trained ensemble model\n",
    "with open(model_path, \"wb\") as model_file:\n",
    "    pickle.dump(final_model, model_file)\n",
    "\n",
    "print(f\" Model saved successfully at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1740818524105,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "GEwhVyiSgGLi",
    "outputId": "33fd7b9f-b536-4e93-ce5e-d4e1854eff87"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained TF-IDF vectorizer\n",
    "vectorizer_path = \"/content/drive/MyDrive/Python/shree/Text_emoji_label/tfidf_vectorizer.pkl\"\n",
    "with open(vectorizer_path, \"wb\") as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n",
    "\n",
    "print(f\" TF-IDF Vectorizer saved successfully at: {vectorizer_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1400878,
     "status": "ok",
     "timestamp": 1740819924986,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "zbzINbAuICSk",
    "outputId": "bc0d26e5-2749-4ae8-b6e4-c3c9336d53c2"
   },
   "outputs": [],
   "source": [
    "# Function to predict user input\n",
    "def predict_user_input(final_model, vectorizer):\n",
    "    while True:\n",
    "        user_text = input(\"\\nEnter a message to classify (or type 'exit' to quit): \")\n",
    "        if user_text.lower() == \"exit\":\n",
    "            print(\"Goodbye! \")\n",
    "            break\n",
    "\n",
    "        # Clean the input text\n",
    "        cleaned_text = clean_text_spacy(user_text)\n",
    "\n",
    "        # Convert to TF-IDF\n",
    "        text_tfidf = vectorizer.transform([cleaned_text])\n",
    "\n",
    "        # Predict\n",
    "        prediction = final_model.predict(text_tfidf)[0]\n",
    "\n",
    "        # Convert numeric prediction to label\n",
    "        label = \"Spam\" if prediction == 1 else \"Ham\"\n",
    "\n",
    "        print(f\"Prediction: {label} \")\n",
    "\n",
    "# Call function with best model and vectorizer\n",
    "predict_user_input(final_model, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1740819943133,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "1BiLQJysoXiV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Store the model performance metrics\n",
    "metrics = {\n",
    "    \"Random Forest\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "        \"Precision\": classification_report(y_test, y_pred_rf, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_rf, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_rf, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "    \"Naïve Bayes\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_nb),\n",
    "        \"Precision\": classification_report(y_test, y_pred_nb, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_nb, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_nb, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_lr),\n",
    "        \"Precision\": classification_report(y_test, y_pred_lr, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_lr, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_lr, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_knn),\n",
    "        \"Precision\": classification_report(y_test, y_pred_knn, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_knn, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_knn, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n",
    "        \"Precision\": classification_report(y_test, y_pred_xgb, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_xgb, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_xgb, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_svm),\n",
    "        \"Precision\": classification_report(y_test, y_pred_svm, output_dict=True)['1']['precision'],\n",
    "        \"Recall\": classification_report(y_test, y_pred_svm, output_dict=True)['1']['recall'],\n",
    "        \"F1-Score\": classification_report(y_test, y_pred_svm, output_dict=True)['1']['f1-score'],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "df_metrics = pd.DataFrame(metrics).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1740820115161,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "8HeTLAIem-H8",
    "outputId": "02584813-3d5b-4e77-a18f-c9b2304334ef"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy Comparison with values on top of bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=df_metrics.index, y=df_metrics[\"Accuracy\"], palette=\"Blues_d\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add accuracy values on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.4f}',  # Format the accuracy to 4 decimal places\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),  # Position it at the top of the bar\n",
    "                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1740821106028,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "_JnPCXMq9M9G",
    "outputId": "626c19a6-2497-4b33-9595-e851cba4b12e"
   },
   "outputs": [],
   "source": [
    "# Plot Precision, Recall, and F1-Score using a bar chart\n",
    "df_metrics[[\"Precision\", \"Recall\", \"F1-Score\"]].plot(kind=\"bar\", stacked=False, figsize=(12, 6), colormap=\"coolwarm\")\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Metrics\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aatEgCTU9kAc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPS2WbNVCx9BS2Ie797lPWC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
