{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4951,
     "status": "ok",
     "timestamp": 1740631740520,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "zZmq6ichi_O1",
    "outputId": "9374e94f-141c-4621-8c31-201d983974f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46560,
     "status": "ok",
     "timestamp": 1740631787084,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "9kDWo5mHer7Z",
    "outputId": "3dfcc7cd-ceed-4606-ab4c-1757426f4cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1903,
     "status": "ok",
     "timestamp": 1740631788994,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "ilOj27cifhx8",
    "outputId": "b642c746-4d7f-405e-d97e-fd96ecf6ebd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EnsembleModel class defined!\n",
      "✅ Ensemble model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, model_1, model_2):\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        prob_1 = self.model_1.predict_proba(X)[:, 1]\n",
    "        prob_2 = self.model_2.predict_proba(X)[:, 1]\n",
    "        avg_prob = (prob_1 + prob_2) / 2\n",
    "        return np.vstack([1 - avg_prob, avg_prob]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.predict_proba(X)[:, 1] > 0.5, 1, 0)\n",
    "\n",
    "print(\" EnsembleModel class defined!\")\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Python/shree/Text_emoji_label/ensemble_model.pkl\", \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "print(\" Ensemble model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1661124,
     "status": "ok",
     "timestamp": 1740633531984,
     "user": {
      "displayName": "1CroreProjects Team",
      "userId": "04780675659999924756"
     },
     "user_tz": -330
    },
    "id": "WDbJPrbdfk15",
    "outputId": "73251da9-5b62-44dc-94a3-74318fd20ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a message to classify (or type 'exit' to quit): exit\n",
      "Goodbye! \n"
     ]
    }
   ],
   "source": [
    "model_path = \"/content/drive/MyDrive/Python/shree/Text_emoji_label/ensemble_model.pkl\"\n",
    "with open(model_path, \"rb\") as model_file:\n",
    "    final_model = pickle.load(model_file)\n",
    "\n",
    "vectorizer_path = \"/content/drive/MyDrive/Python/shree/Text_emoji_label/tfidf_vectorizer.pkl\"\n",
    "with open(vectorizer_path, \"rb\") as vec_file:\n",
    "    vectorizer = pickle.load(vec_file)\n",
    "\n",
    "def clean_text_spacy(text):\n",
    "    if pd.isna(text): \n",
    "        return \"\"\n",
    "\n",
    "    text = str(text) \n",
    "    text = emoji.demojize(text) \n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) \n",
    "    text = text.lower().strip()\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def predict_user_input(final_model, vectorizer):\n",
    "    while True:\n",
    "        user_text = input(\"\\nEnter a message to classify (or type 'exit' to quit): \")\n",
    "        if user_text.lower() == \"exit\":\n",
    "            print(\"Goodbye! \")\n",
    "            break\n",
    "\n",
    "        cleaned_text = clean_text_spacy(user_text)\n",
    "\n",
    "        text_tfidf = vectorizer.transform([cleaned_text])\n",
    "\n",
    "        prediction = final_model.predict(text_tfidf)[0]\n",
    "\n",
    "        label = \"Spam\" if prediction == 1 else \"Ham\"\n",
    "\n",
    "        print(f\"Prediction: {label} \")\n",
    "\n",
    "predict_user_input(final_model, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgQkZV3Th_AF"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPPTpm0yEzeG/odazp091WP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
